optimizer: {
  type: AdamW,
  part: dapt,
  kwargs: {
    lr: 0.0005,
    weight_decay: 0.05
  } }

scheduler: {
  type: CosLR,
  kwargs: {
    epochs: 300,
    initial_epochs: 10
  } }

dataset: {
  train: { _base_: cfgs/dataset_configs/ModelNet40.yaml,
           others: { subset: 'train' } },
  val: { _base_: cfgs/dataset_configs/ModelNet40.yaml,
         others: { subset: 'test' } },
  test: { _base_: cfgs/dataset_configs/ModelNet40.yaml,
          others: { subset: 'test' } } }
model: {
  NAME: PointTransformer_DAPT,
  trans_dim: 384,
  depth: 12,
  drop_path_rate: 0.1,
  drop_rate: 0.,
  cls_dim: 40,
  num_heads: 6,
  group_size: 32,
  num_group: 64,
  encoder_dims: 384,
  rank: 72,
  drop_adapter_rate: 0,
  class_token: "use",
  prompt_token: "None",
  patch_token: "max",
}


npoints: 1024
total_bs: 32
step_per_update: 1
max_epoch: 300
grad_norm_clip: 10